{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K  \u001b[31m×\u001b[0m No solution found when resolving dependencies for split                         \u001b[0m\n",
      "  \u001b[31m│\u001b[0m (python_full_version >= '3.13'):\n",
      "\u001b[31m  ╰─▶ \u001b[0mBecause only the following versions of google-generativeai are\n",
      "\u001b[31m      \u001b[0mavailable:\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.1.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.2.1\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.2.2\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.3.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.3.1\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.3.2\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.4.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.4.1\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.5.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.5.1\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.5.2\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.5.3\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.5.4\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.6.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.7.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.7.1\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.7.2\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.8.0\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.8.1\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.8.2\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.8.3\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.8.4\n",
      "\u001b[31m      \u001b[0m    google-generativeai==0.8.5\n",
      "\u001b[31m      \u001b[0mand google-generativeai==0.1.0 depends on\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.2.0, we can\n",
      "\u001b[31m      \u001b[0mconclude that google-generativeai<0.2.0 depends on\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.2.0.\n",
      "\u001b[31m      \u001b[0mAnd because google-generativeai==0.2.0 depends\n",
      "\u001b[31m      \u001b[0mon google-ai-generativelanguage==0.3.2 and\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.3.3, we can conclude that\n",
      "\u001b[31m      \u001b[0mgoogle-generativeai<0.3.0 depends on one of:\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.3.2,<=0.3.3\n",
      "\n",
      "\u001b[31m      \u001b[0mAnd because google-generativeai>=0.3.0,<=0.4.1\n",
      "\u001b[31m      \u001b[0mdepends on google-ai-generativelanguage==0.4.0 and\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.6.1, we can conclude that\n",
      "\u001b[31m      \u001b[0mgoogle-generativeai<0.5.1 depends on one of:\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.3.2,<=0.3.3\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.4.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.6.1\n",
      "\n",
      "\u001b[31m      \u001b[0mAnd because google-generativeai>=0.5.1,<=0.5.2\n",
      "\u001b[31m      \u001b[0mdepends on google-ai-generativelanguage==0.6.2 and\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.6.3, we can conclude that\n",
      "\u001b[31m      \u001b[0mgoogle-generativeai<0.5.4 depends on one of:\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.3.2,<=0.3.3\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.4.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.6.1,<=0.6.3\n",
      "\n",
      "\u001b[31m      \u001b[0mAnd because google-generativeai>=0.5.4,<=0.6.0\n",
      "\u001b[31m      \u001b[0mdepends on google-ai-generativelanguage==0.6.4 and\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.6.5, we can conclude that\n",
      "\u001b[31m      \u001b[0mgoogle-generativeai<0.7.1 depends on one of:\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.3.2,<=0.3.3\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.4.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.6.1,<=0.6.5\n",
      "\n",
      "\u001b[31m      \u001b[0mAnd because google-generativeai>=0.7.1,<=0.7.2\n",
      "\u001b[31m      \u001b[0mdepends on google-ai-generativelanguage==0.6.6 and\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.6.9, we can conclude that\n",
      "\u001b[31m      \u001b[0mgoogle-generativeai<0.8.2 depends on one of:\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.3.2,<=0.3.3\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.4.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.6.1,<=0.6.6\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.6.9\n",
      "\n",
      "\u001b[31m      \u001b[0mAnd because google-generativeai>=0.8.4 depends\n",
      "\u001b[31m      \u001b[0mon google-ai-generativelanguage==0.6.15 and\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage==0.6.10, we can conclude that all versions\n",
      "\u001b[31m      \u001b[0mof google-generativeai depend on one of:\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.2.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.3.2,<=0.3.3\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.4.0\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.6.1,<=0.6.6\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage>=0.6.9,<=0.6.10\n",
      "\u001b[31m      \u001b[0m    google-ai-generativelanguage==0.6.15\n",
      "\n",
      "\u001b[31m      \u001b[0mAnd because langchain-google-genai>=2.1.4 depends on\n",
      "\u001b[31m      \u001b[0mgoogle-ai-generativelanguage>=0.6.18 and only the following versions of\n",
      "\u001b[31m      \u001b[0mlangchain-google-genai are available:\n",
      "\u001b[31m      \u001b[0m    langchain-google-genai<=2.1.4\n",
      "\u001b[31m      \u001b[0m    langchain-google-genai==2.1.5\n",
      "\u001b[31m      \u001b[0mwe can conclude that all versions of google-generativeai and\n",
      "\u001b[31m      \u001b[0mlangchain-google-genai>=2.1.4 are incompatible.\n",
      "\u001b[31m      \u001b[0mAnd because your project depends on google-generativeai and\n",
      "\u001b[31m      \u001b[0mlangchain-google-genai>=2.1.4, we can conclude that your project's\n",
      "\u001b[31m      \u001b[0mrequirements are unsatisfiable.\n",
      "\n",
      "\u001b[31m      \u001b[0m\u001b[36m\u001b[1mhint\u001b[0m\u001b[39m\u001b[1m:\u001b[0m Pre-releases are available for `\u001b[36mgoogle-generativeai\u001b[39m` in the\n",
      "\u001b[31m      \u001b[0mrequested range (e.g., \u001b[36m0.1.0rc3\u001b[39m), but pre-releases weren't enabled (try:\n",
      "\u001b[31m      \u001b[0m`\u001b[32m--prerelease=allow\u001b[39m`)\n",
      "\u001b[36m  help: \u001b[0mIf you want to add the package regardless of the failed resolution,\n",
      "        provide the `\u001b[32m--frozen\u001b[39m` flag to skip locking and syncing.\n"
     ]
    }
   ],
   "source": [
    "!uv add gradio google-generativeai python-dotenv nest-asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "from datetime import datetime\n",
    "import nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m nest_asyncio.apply()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mload_dotenv\u001b[49m(override=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "nest_asyncio.apply()\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_travel_manager= \"\"\"\n",
    "You act as a travel agent. A user tells you about their trip intention and your role is to find\n",
    "what they are interested in doing and collect all the information needed to plan a trip and select\n",
    "the right flight options and hotel. You keep asking questions and clarifications to the user\n",
    "until you decide you have enough details to make a booking.\n",
    "You are always polite and amicable to the user, and you are always transparent about the fact that you\n",
    "are an AI Agent.\n",
    "Once you have all the information required and you think the information can be passed to the operational team,\n",
    "you thank the user, then record all the information in your memory so that it can be passed on the next agent\n",
    "for research\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelAgentBot:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize the travel agent bot with OpenAI API\"\"\"\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "        self.conversation_history = []\n",
    "        \n",
    "        # Travel agent system prompt\n",
    "        self.system_prompt = instructions_travel_manager\n",
    "\n",
    "    def generate_response(self, user_message: str) -> str:\n",
    "        \"\"\"Generate a response using OpenAI\"\"\"\n",
    "        try:\n",
    "            # Build messages for the conversation\n",
    "            messages = [{\"role\": \"system\", \"content\": self.system_prompt}]\n",
    "            \n",
    "            # Add conversation history for context\n",
    "            for exchange in self.conversation_history[-5:]:  # Keep last 5 exchanges\n",
    "                messages.append({\"role\": \"user\", \"content\": exchange['user']})\n",
    "                messages.append({\"role\": \"assistant\", \"content\": exchange['assistant']})\n",
    "            \n",
    "            # Add current user message\n",
    "            messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "            \n",
    "            # Generate response\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",  # or \"gpt-4\" if you have access\n",
    "                messages=messages,\n",
    "                max_tokens=1000,\n",
    "                temperature=0.7\n",
    "            )\n",
    "            \n",
    "            assistant_response = response.choices[0].message.content\n",
    "            \n",
    "            # Store in conversation history\n",
    "            self.conversation_history.append({\n",
    "                \"user\": user_message,\n",
    "                \"assistant\": assistant_response,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            return assistant_response\n",
    "            \n",
    "        except Exception as e:\n",
    "            return f\"I'm sorry, I encountered an error: {str(e)}. Please try again.\"\n",
    "\n",
    "    def clear_history(self):\n",
    "        \"\"\"Clear conversation history\"\"\"\n",
    "        self.conversation_history = []\n",
    "        return \"Conversation history cleared. How can I help you plan your next adventure?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "bot = TravelAgentBot(API_KEY)\n",
    "print(\"✅ Travel Agent Bot initialized successfully!\")\n",
    "print(\"🌍 Ready to help you plan your next adventure!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_bot(message: str, history: List[Tuple[str, str]]) -> Tuple[List[Tuple[str, str]], str]:\n",
    "    \"\"\"Handle chat interaction\"\"\"\n",
    "    if not message.strip():\n",
    "        return history, \"\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = bot.generate_response(message)\n",
    "    \n",
    "    # Update chat history\n",
    "    history.append((message, response))\n",
    "    \n",
    "    return history, \"\"\n",
    "\n",
    "def clear_chat():\n",
    "    \"\"\"Clear chat history\"\"\"\n",
    "    bot.clear_history()\n",
    "    return [], \"\"\n",
    "\n",
    "def get_conversation_info():\n",
    "    \"\"\"Get conversation statistics\"\"\"\n",
    "    return bot.get_conversation_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_travel_bot_interface():\n",
    "    with gr.Blocks(\n",
    "        title=\"🌍 AI Travel Agent\",\n",
    "        theme=gr.themes.Soft(),\n",
    "    ) as demo:\n",
    "        \n",
    "        # Header\n",
    "        gr.HTML(\"\"\"\n",
    "        <div style=\"text-align: center; padding: 20px; background: linear-gradient(90deg, #4CAF50, #45a049); color: white; border-radius: 10px; margin-bottom: 20px;\">\n",
    "            <h1>🌍 AI Travel Agent Bot</h1>\n",
    "            <p>Your personal travel planning assistant powered by Gemini 1.5 Flash</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "        \n",
    "        # Main chat interface\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=4):\n",
    "                chatbot = gr.Chatbot(\n",
    "                    label=\"💬 Chat with your Travel Agent\",\n",
    "                    height=500,\n",
    "                    show_label=True,\n",
    "                    container=True,\n",
    "                    bubble_full_width=False,\n",
    "                    avatar_images=(\"🧳\", \"🤖\")\n",
    "                )\n",
    "                \n",
    "                with gr.Row():\n",
    "                    msg_input = gr.Textbox(\n",
    "                        label=\"Your message\",\n",
    "                        placeholder=\"Ask me about destinations, hotels, activities, or travel tips...\",\n",
    "                        lines=2,\n",
    "                        show_label=False,\n",
    "                        container=False\n",
    "                    )\n",
    "                    \n",
    "                with gr.Row():\n",
    "                    send_btn = gr.Button(\"Send ✈️\", variant=\"primary\", size=\"sm\")\n",
    "                    clear_btn = gr.Button(\"Clear Chat 🗑️\", variant=\"secondary\", size=\"sm\")\n",
    "            \n",
    "            # Sidebar with info and controls\n",
    "            with gr.Column(scale=1):\n",
    "                gr.HTML(\"<h3>🔧 Controls</h3>\")\n",
    "                \n",
    "                info_btn = gr.Button(\"📊 Conversation Info\", size=\"sm\")\n",
    "                info_output = gr.Textbox(\n",
    "                    label=\"Conversation Summary\",\n",
    "                    lines=6,\n",
    "                    max_lines=10,\n",
    "                    interactive=False\n",
    "                )\n",
    "                \n",
    "                gr.HTML(\"\"\"\n",
    "                <div style=\"margin-top: 20px; padding: 10px; background-color: #e8f5e8; border-radius: 5px;\">\n",
    "                    <h4>💡 Quick Tips:</h4>\n",
    "                    <ul style=\"font-size: 12px;\">\n",
    "                        <li>Be specific about dates and budget</li>\n",
    "                        <li>Mention travel preferences</li>\n",
    "                        <li>Ask for detailed itineraries</li>\n",
    "                        <li>Request local recommendations</li>\n",
    "                    </ul>\n",
    "                </div>\n",
    "                \"\"\")\n",
    "        \n",
    "        # Example questions section\n",
    "        with gr.Row():\n",
    "            gr.HTML(\"\"\"\n",
    "            <div style=\"margin-top: 20px; padding: 15px; background-color: #f0f8ff; border-radius: 10px;\">\n",
    "                <h3>💡 Example Questions to Get Started:</h3>\n",
    "                <div style=\"display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin-top: 10px;\">\n",
    "                    <div>\n",
    "                        <strong>🏝️ Destination Planning:</strong>\n",
    "                        <ul>\n",
    "                            <li>\"Plan a 7-day trip to Japan in spring\"</li>\n",
    "                            <li>\"Best budget destinations in Europe for couples\"</li>\n",
    "                            <li>\"Family-friendly activities in Bali\"</li>\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                    <div>\n",
    "                        <strong>🍽️ Food & Culture:</strong>\n",
    "                        <ul>\n",
    "                            <li>\"Food tour itinerary for Thailand\"</li>\n",
    "                            <li>\"Cultural etiquette tips for visiting Morocco\"</li>\n",
    "                            <li>\"Best local markets in Istanbul\"</li>\n",
    "                        </ul>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\")\n",
    "        \n",
    "        # Event handlers\n",
    "        send_btn.click(\n",
    "            chat_with_bot,\n",
    "            inputs=[msg_input, chatbot],\n",
    "            outputs=[chatbot, msg_input]\n",
    "        )\n",
    "        \n",
    "        msg_input.submit(\n",
    "            chat_with_bot,\n",
    "            inputs=[msg_input, chatbot],\n",
    "            outputs=[chatbot, msg_input]\n",
    "        )\n",
    "        \n",
    "        clear_btn.click(\n",
    "            clear_chat,\n",
    "            outputs=[chatbot, msg_input]\n",
    "        )\n",
    "        \n",
    "        info_btn.click(\n",
    "            get_conversation_info,\n",
    "            outputs=[info_output]\n",
    "        )\n",
    "    \n",
    "    return demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Launch the interface inline in notebook\n",
    "print(\"🚀 Starting Travel Agent Bot interface...\")\n",
    "print(\"📱 The interface will appear below in this notebook\")\n",
    "\n",
    "# Create the demo\n",
    "demo = create_travel_bot_interface()\n",
    "\n",
    "# Enable queue for better notebook performance\n",
    "demo.queue()\n",
    "\n",
    "# Launch inline within the notebook\n",
    "demo.launch(\n",
    "    debug=True,\n",
    "    share=False,\n",
    "    inbrowser=False,  # Keep in notebook\n",
    "    inline=True,      # Display inline\n",
    "    height=600,       # Set height\n",
    "    show_error=True,\n",
    "    quiet=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
